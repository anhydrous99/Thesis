\documentclass{article}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage[utf8]{inputenc}

\usepackage{mathtools}
\usepackage{tabularx}
\DeclarePairedDelimiter\ceil{\lceil}{\rceil}
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}

\title{Artificial Intelligence to Reinforcement Learning}
\author{Armando Herrera}

\begin{document}
\maketitle

Here I'll go over the fundamentals of Neural Network and Machine Learning as well as the some applications and practical applications. Then I'll go over the fundamentals of Reinforcement Learning from the typical formalism to some of the latest methods and algorithms.

Before we even go over neural network, I do believe in having a strong foundation in the subject and a clear mathematical formalism. This allows for a subject's mathematical description of methods to speak to us in a clear and understandable language forming a clear picture.

\section{Introductory Mathematics}

\subsection{Formalism}

In this paper, I heavily rely on the formalism typically expressed in linear algebra textbooks. This allows me to relay the most important information, intuitively, while preserving exactness.

To describe a scalar, mathematically, a standard letter a used. For instance $a=1$, where I assign the variable $a$ the scalar value of $1$. To describe a vector, an arrow is placed above a variable to denote it as a vector, $\vec{v}=\vec{0}$ denotes a variable $\vec{v}$ assigned the zero vector. A vector can be described as an element of n-dimensional Euclidean Space where each element of the vector denotes an axis of said space. $$\vec{x}=\begin{bmatrix}1 & 2 & 3\end{bmatrix}$$ is an example vector in 3 dimensional euclidean space. This same vector is denoted as a row-wise vector, where all the elements of the vector are on a single row, a column-wise vector would look like $$\vec{x}=\begin{bmatrix}1 \\ 2 \\ 3\end{bmatrix}.$$ The significance of the distinctions between a row-wise and column-wise vector are show when going over the matrix as in some operations they have different results and making a distinction matters. From now on when a vector is shown and is not other wise said assume the vector is in column-wise form. 

Another form that a vector can be expressed in is via summation notation. In this notation, we must first define the following unit vectors, $$\hat{r}_1=\begin{bmatrix}1 \\ 0 \\ \vdots \\ 0\end{bmatrix},\hat{r}_2=\begin{bmatrix}0 \\ 1 \\ \vdots \\ 0\end{bmatrix},\dots,\hat{r}_n=\begin{bmatrix}0 \\ 0 \\ \vdots \\ 1\end{bmatrix} .$$ Each element of said vector can then be denoted as $$\vec{x}=x_1 \hat{r}_1 + x_2 \hat{r}_2 + \dots + x_n \hat{r}_n$$ and finally using sigma notation, $$\vec{x}=\sum_{i=1}^n x_i \hat{r}_i.$$ This notation is important to properly display information and proofs that would be difficult to display using the previously show forms. One example proof is the proof for the vector's associativity axiom, $\vec{u}+(\vec{v}+\vec{w})=(\vec{u}+\vec{v})+\vec{w}$.
\begin{proof}
\begin{align*}
\vec{u}+(\vec{v}+\vec{w})&=(\vec{u}+\vec{v})+\vec{w} \\
&=\bigg(\sum_{i=1}^nu_i \hat{r}_i+\sum_{j=1}^n v_j \hat{r}_j\bigg)+\sum_{k=1}^n w_k \hat{r}_k\\
&=\sum_{i=1}^n (u_i\hat{r}_i + v_i\hat{r}_i) + w_i\hat{r}_i\\
&=\sum_{i=1}^n \big((u_i + v_i) + w_i\big)r_i\\
&=\sum_{i=1}^n \big(u_i+(v_i+w_i)\big)r_i&\text{scalar's associativity}\\
&=\vec{u}+(\vec{v}+\vec{w})
\end{align*}
\end{proof}

\subsection{Matrix Operations}

In this section, I will go over the common matrix operations that are used in Machine Learning. Firstly, a matrix is basically a table of mathematical expression or numbers arranged in columns and rows. For example, $$A=\begin{bmatrix} 1 & 2 \\ 3 & 4 \end{bmatrix}.$$ Both row vectors and column vectors can be seen as matrices with a single row or a single column. In this paper, when ever a letter is capitalized it means that it represent a matrix. When a matrix is show as $[A]_{ij}$ this means we are talking about the element in the $i$th row and the $j$th column.

\subsubsection{Component-wise Operations}

Component wise operations like multiplication, addition, and subtraction can be denoted on a per component basis. $$[A\square B]_{ij}=[A]_{ij} \square [B]_{ij}$$

The $\square$ symbols represent the different possible component-wise operations like multiplication, add, subtraction, and even division.

\subsubsection{Matrix Multiplication}

Matrix Multiplication is the most heavily used operation in Machine Learning. It's definition is simple, in summation notation, $$[AB]_{ij}=\sum_{k=1}^n [A]_{ik}[B]_{kj}.$$

\subsubsection{Kronecker Product}

Kronecker is a little less known but extremely use product that makes mathematical definitions in machine learning simpler. It is defined as $$[A\otimes B]_{ij}=[A]_{\floor{(i-1)/p}+1,\floor{(j-1)/q}+1}[B]_{(i-1)\%p+1,(j-1)\%q+1}.$$ A matrix with dimensions $p\times q$ will result in a matrix of dimensions $pm\times qn$.

\subsubsection{Matrix Transpose}

The transpose operation is also used extensively. It is defined as $$[A^T]_{ij}=[A]_{ji}.$$

\subsection{Vector Operations}

Both single rowed, and single columned matrices are vectors, which means we can borrow some of the operations, for instance, the component-wise operations.

The Dot Product is defined as $$\vec{a}\cdot \vec{b}=\sum_{i=1}^n a_i b_i.$$ Notice, the Dot Product basically is Matrix Multiplication between two vectors, one in the form of a row vector and the other as a column vector. 

\begin{proof}
\begin{align*}
\vec{a}\cdot \vec{b}&=\vec{a}\vec{b}^T\\
&=\begin{bmatrix}a_1 & a_2 & \dots \end{bmatrix}
\begin{bmatrix}b_1 \\ b_2 \\ \vdots \end{bmatrix}\\
&=\sum_{i=1}^na_i b_i \\
&=\vec{a}\cdot \vec{b}
\end{align*}
\end{proof}

\section{The Agent and it's Environment}

According to "Artificial Intelligence: A Modern Approach" by Russel and Norvig an agent as "anything that can be viewed as perceiving its environment through sensors and acting upon that environment through actuators." For instance, an autonomous car will have the roads, and the area around the roads as the environment perceives through the various IR, radar, and visual sensors around the car. The autonomous car will interact with the environment through its various actuators, the accelerator, the brake, and the steering. 

In terms of the environment, I will describe the agent as a satellite that is orbiting a pseudo-earth with a heavier atmosphere, to simulate an accelerated orbital decay. The orbital decay is accelerated because the orbital decay forces are relatively minute, so creating an agent in a reasonable amount of time with a reasonable amount of computational resources is done. Of course, this is a hyper-parameter that can be changed in the future to continue research into creating a more long-term agent.  

The satellite's actuators are its engines that generate thrust and its angle of thrust. The goal of the agent would then be to try its best to maintain its orbit. The performance measure would be a function of the amount of time it stays within a certain threshold from its orbit altitude. A more detailed and mathematical description is explained in a later section.

\begin{table}
\caption{A simple description of the environment.}
\begin{tabularx}{\columnwidth}{|X||X|X|X|X|} \hline
Agent Type & Performance Measure & Environment & Actuators & Sensors \\ \hline
Satellite  & How long the satellite is able to maintain it's orbit with the amount of fuel it has. & 
Low Earth Orbit & The engine and it's angle of thrust. & Relative position, velocity data with respect to earth and it's target orbit, as well as it's current angle and thrust. \\ \hline
\end{tabularx}
\end{table}

The environment is static, single-agent, fully observable sequential, and continuous. Static in that the agent does not have to keep cognizant while it is deliberating. Single-agent, while the environment is expanded to accommodate multiple agents to accelerate training to keep it simple, it is a single-agent environment. It is sequential where the agent's experience cannot be divided into atomic episodes, and every time step requires the last. Finally, it is continuous as the position, velocity, and other attributes are continuous. The actions of thrust and angle will be continuous. 

\section{Neural Networks}

The history of neural networks goes back to the 1940 but was really popularized with the perceptron in the 50s and 60s where the perceptron was implemented on an IBM 704.

\subsection{Perceptrons}

In the simplest of thinking a perceptron simply is a single-layer neural network. It basically is a piecewise function where a weights $w$ and bias $b$ determine the output. $$f(\vec{x})=\begin{cases}
1 \mbox{ if } \vec{w}\cdot \vec{x}+b>0 \\
0 \mbox{ otherwise }
\end{cases}$$ Where $\vec{w}$  is the weight vector, $b$ is the bias, and $x$ is the input vector. 

\subsection{Recurrent Networks}

\subsection{Convolution Networks}


\section{Reinforcement Learning}

\subsection{Cross-Entropy Method}

\subsection{Q-Learning}

\subsection{TRPO}

\subsection{DQN}

\subsection{PPO}

\end{document}